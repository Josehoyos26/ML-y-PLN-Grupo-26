{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>State</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34995</td>\n",
       "      <td>2017</td>\n",
       "      <td>9913</td>\n",
       "      <td>FL</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Wrangler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37895</td>\n",
       "      <td>2015</td>\n",
       "      <td>20578</td>\n",
       "      <td>OH</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe4WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18430</td>\n",
       "      <td>2012</td>\n",
       "      <td>83716</td>\n",
       "      <td>TX</td>\n",
       "      <td>BMW</td>\n",
       "      <td>X5AWD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24681</td>\n",
       "      <td>2014</td>\n",
       "      <td>28729</td>\n",
       "      <td>OH</td>\n",
       "      <td>Cadillac</td>\n",
       "      <td>SRXLuxury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26998</td>\n",
       "      <td>2013</td>\n",
       "      <td>64032</td>\n",
       "      <td>CO</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Wrangler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Year  Mileage State       Make      Model\n",
       "0  34995  2017     9913    FL       Jeep   Wrangler\n",
       "1  37895  2015    20578    OH  Chevrolet   Tahoe4WD\n",
       "2  18430  2012    83716    TX        BMW      X5AWD\n",
       "3  24681  2014    28729    OH   Cadillac  SRXLuxury\n",
       "4  26998  2013    64032    CO       Jeep   Wrangler"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480        0           0            0         1   \n",
       "11   13995  2014    39972        0           0            0         0   \n",
       "167  17941  2016    18989        0           0            0         0   \n",
       "225  12493  2014    51330        0           0            0         1   \n",
       "270   7994  2007   116065        0           1            0         0   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7            0          0           0  \n",
       "11           1          0           0  \n",
       "167          0          1           0  \n",
       "225          0          0           0  \n",
       "270          0          0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(X, y, max_depth, min_samples_split, depth=0):\n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Comprobar si hemos alcanzado la profundidad máxima o si tenemos menos muestras que las muestras mínimas para dividir\n",
    "    if depth >= max_depth or n_samples < min_samples_split:\n",
    "        return np.mean(y)\n",
    "\n",
    "    # Encontrar la característica y el umbral que minimizan el error\n",
    "    best_loss = np.inf\n",
    "    best_feature, best_threshold = None, None\n",
    "    for feature in range(n_features):\n",
    "        thresholds = np.unique(X[:, feature])\n",
    "        for threshold in thresholds:\n",
    "            y_left = y[X[:, feature] < threshold]\n",
    "            y_right = y[X[:, feature] >= threshold]\n",
    "            if len(y_left) == 0 or len(y_right) == 0:\n",
    "                continue\n",
    "            loss = np.sum((y_left - np.mean(y_left))**2) + np.sum((y_right - np.mean(y_right))**2)\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_feature = feature\n",
    "                best_threshold = threshold\n",
    "\n",
    "    # Verificar si no pudimos encontrar una división que reduzca el error\n",
    "    if best_feature is None:\n",
    "        return np.mean(y)\n",
    "\n",
    "    # Dividir los datos en nodos secundarios izquierdo y derecho\n",
    "    left_indices = X[:, best_feature] < best_threshold\n",
    "    X_left, y_left = X[left_indices], y[left_indices]\n",
    "    X_right, y_right = X[~left_indices], y[~left_indices]\n",
    "\n",
    "    # Crear los nodos secundarios izquierdo y derecho\n",
    "    left = build_tree(X_left, y_left, max_depth, min_samples_split, depth+1)\n",
    "    right = build_tree(X_right, y_right, max_depth, min_samples_split, depth+1)\n",
    "\n",
    "    # Crear el nodo actual\n",
    "    return {'feature': best_feature, 'threshold': best_threshold, 'left': left, 'right': right}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción del árbol\n",
    "max_depth = 5\n",
    "min_samples_split = 10\n",
    "tree = build_tree(X.values, y.values, max_depth, min_samples_split)\n",
    "\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(x, tree):\n",
    "    # Función auxiliar para predecir una muestra utilizando el árbol de decisión\n",
    "    if x[tree['feature']] < tree['threshold']:\n",
    "        if isinstance(tree['left'], dict):\n",
    "            return predict_sample(x, tree['left'])\n",
    "        else:\n",
    "            return tree['left']\n",
    "    else:\n",
    "        if isinstance(tree['right'], dict):\n",
    "            return predict_sample(x, tree['right'])\n",
    "        else:\n",
    "            return tree['right']\n",
    "\n",
    "def predict(X, tree):\n",
    "    # Función para predecir un conjunto de datos utilizando el árbol de decisión\n",
    "    y_pred = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        y_pred[i] = predict_sample(X[i], tree)\n",
    "    return y_pred\n",
    "\n",
    "# Predecir los valores de y utilizando el conjunto de prueba y el árbol de decisión\n",
    "y_pred = predict(X_test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calcular RMSE y MAE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tree = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "reg_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg_tree.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el RMSE y MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('RMSE:', rmse)\n",
    "print('MAE:', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Ajustar una línea de tendencia\n",
    "z = np.polyfit(y_test, y_pred, 1)\n",
    "p = np.poly1d(z)\n",
    "\n",
    "# Graficar la dispersión y la línea de tendencia\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot(y_test, p(y_test), \"r--\")\n",
    "plt.xlabel('Precios reales')\n",
    "plt.ylabel('Precios predichos')\n",
    "plt.title('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de clasificación y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2\n",
    "\n",
    "# Se crea un arreglo de 1 a 20\n",
    "np.random.seed(1)\n",
    "\n",
    "# Impresión de arreglo y muestreo aleatorio\n",
    "nums = np.arange(1, 21)\n",
    "print('Arreglo:', nums)\n",
    "print('Muestreo aleatorio: ', np.random.choice(a=nums, size=20, replace=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de 10 muestras de bootstrap \n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 10\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción un árbol de decisión para cada muestra boostrap\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Definición del modelo usando DecisionTreeRegressor de sklearn\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame para guardar las predicciones de cada árbol\n",
    "y_pred = pd.DataFrame(columns=['Price'])\n",
    "\n",
    "# Entrenamiento de un árbol sobre cada muestra boostrap y predicción sobre los datos de test\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train = X_train.iloc[sample, 0:]\n",
    "    y_train = y_train.iloc[sample]\n",
    "    treereg.fit(X_train, y_train)\n",
    "    y_pred_i = treereg.predict(X_test)\n",
    "    y_pred['Price' + str(i+1)] = y_pred_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempeño de cada árbol\n",
    "for i in range(n_B):\n",
    "    print('Árbol ', i, 'tiene un error: ', np.sqrt(mean_squared_error(y_pred.iloc[:,i], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones promedio para cada obserbación del set de test\n",
    "y_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error al promediar las predicciones de todos los árboles\n",
    "np.sqrt(mean_squared_error(y_test, y_pred.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de clasificación y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(max_features=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from math import log\n",
    "import numpy as np\n",
    "\n",
    "features = X.columns\n",
    "n_features=len(features)\n",
    "\n",
    "clfBag = BaggingRegressor(n_estimators=10, max_features=max(1, int(log(n_features))))\n",
    "clfBag.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE Bagging:\n",
      "5535694.2886524685\n"
     ]
    }
   ],
   "source": [
    "prediccionclfBag = clfBag.predict(X_test)\n",
    "MSE_clfBag = np.average(np.square(prediccionclfBag-y_test))\n",
    "print('\\nMSE Bagging:')\n",
    "print(MSE_clfBag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para clasificación  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=9, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clfRF = RandomForestRegressor(n_estimators=100, max_features=n_features, random_state=1, n_jobs=-1)\n",
    "clfRF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE Bagging:\n",
      "3083089.1739264703\n"
     ]
    }
   ],
   "source": [
    "prediccionclfRF = clfRF.predict(X_test)\n",
    "MSE_clfRF = np.average(np.square(prediccionclfRF-y_test))\n",
    "print('\\nMSE Bagging:')\n",
    "print(MSE_clfRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para clasificación, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de clasificación con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para clasificación, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
